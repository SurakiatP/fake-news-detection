{"duration": 0.09529280662536621, "input_args": {"text": "'DETROIT  \u2014   The race by automakers and technology firms to develop   cars has been fueled by the belief that computers can operate a vehicle more safely than human drivers. But that view is now in question after the revelation on Thursday that the driver of a Tesla Model S electric sedan was killed in an accident when the car was in   mode. Federal regulators, who are in the early stages of setting guidelines for autonomous vehicles, have opened a formal investigation into the incident, which occurred on May 7 in Williston, Fla. In a statement, the National Highway Traffic Safety Administration said preliminary reports indicated that the crash occurred when a   made a left turn in front of the Tesla, and the car failed to apply the brakes. It is the first known fatal accident involving a vehicle being driven by itself by means of sophisticated computer software, sensors, cameras and radar. The safety agency did not identify the Tesla driver who was killed. But the Florida Highway Patrol identified him as Joshua Brown, 40, of Canton, Ohio. He was a Navy veteran who owned a technology consulting firm. In a news release, Tesla on Thursday described him as a man \u201cwho spent his life focused on innovation and the promise of technology and who believed strongly in Tesla\u2019s mission. \u201d Mr. Brown posted videos of himself riding in autopilot mode. \u201cThe car\u2019s doing it all itself,\u2019\u2019 he said in one, smiling as he took his hands from the steering wheel. In another, he praised the system for saving his car from an accident. The death is a blow to Tesla at a time when the company is pushing to expand its product lineup from expensive electric vehicles to more mainstream models. The company on Thursday declined to say whether the technology or the driver or either were at fault in the accident. In its news release it said, \u201cNeither autopilot nor the driver noticed the white side of the   against a brightly lit sky, so the brake was not applied. \u201d The crash also casts doubt on whether autonomous vehicles in general can consistently make      driving decisions on the highway. And other companies are increasing investments in   technology. Google, for example, recently announced plans to adapt 100 Chrysler minivans for autonomous driving. Earlier this year, G. M. acquired the software firm Cruise Automation to accelerate its own   applications. Even as the companies conduct many tests on autonomous vehicles at both private facilities and on public highways, there is skepticism that the technology has progressed far enough for the government to approve cars that totally drive themselves. The traffic safety agency said it was working with the Florida Highway Patrol in the inquiry into Mr. Brown\u2019s fatal accident. The agency cautioned that the opening of an investigation did not mean it thought there was a defect in the vehicle being examined. The federal traffic safety agency is nearing the release of a new set of guidelines and regulations regarding the testing of   vehicles on public roads. They are expected to be released in July. At a recent technology conference in Novi, Mich. the agency\u2019s leader, Mark Rosekind, said   cars should at least be twice as safe as human drivers to result in a significant reduction in roadway deaths. \u201cWe need to start with two times better,\u2019\u2019 Mr. Rosekind said. \u201cWe need to set a higher bar if we expect safety to actually be a benefit here. \u201d Karl Brauer, an analyst with the auto research firm Kelley Blue Book, said the accident served as a signal that the technology might not be as advanced and ready for the market as some proponents have suggested. \u201cThis is a bit of a   call,\u201d Mr. Brauer said. \u201cPeople who were maybe too aggressive in taking the position that we\u2019re almost there, this technology is going to be in the market very soon, maybe need to reassess that. \u201d Tesla said in its news release that it had informed the traffic safety agency about the accident \u201cimmediately after it occurred. \u201d But the company reported it publicly only on Thursday, after learning that the agency had begun to investigate. Mr. Brown had spent 11 years in the Navy and then founded a technology consulting company, Nexu Innovations, according to a May obituary of Mr. Brown in The Greensburg Tribune Review in Westmoreland County, Pa. where he had formerly lived. The Nexu Innovations website, describing Mr. Brown as founder and owner, said that in the Navy he had been on active duty as a \u201cmaster explosive ordnance disposal technician,\u201d including a stint with the Naval Special Warfare Development Group, which is commonly known as SEAL Team 6. Ricky Hammer, a retired Navy master chief who worked with Mr. Brown at the development group, said Mr. Brown had strong computer skills and \u201cwas the equivalent of an electrical engineer even though he didn\u2019t have the degree. \u201d In Iraq in 2006, he said, Mr. Brown played a crucial role in preparing captured explosive projectiles for shipment to the United States to support efforts to improve the armor on military vehicles. \u201cHe did it by being very aggressive,\u201d Mr. Hammer said, noting that Mr. Brown helped to collect the projectiles after raids on   shops and would   them to determine their contents. In the past, Elon Musk, the Tesla chief executive, has praised the company\u2019s   feature, introduced in the Model S last fall, as \u201cprobably better than a person right now. \u201d But in its statement on Thursday, the company cautioned that it was still only a test feature and noted that its use \u2018\u2018requires explicit acknowledgment that the system is new technology. \u2019\u2019 It noted that when a driver activated the system, an acknowledgment box popped up, explaining that the autopilot mode \u201cis an assist feature that requires you to keep your hands on the steering wheel at all times. \u201d'"}, "time": 1742562202.3079722}