{"duration": 0.08114171028137207, "input_args": {"text": "'There isn\u2019t any evidence to support President Trump\u2019s assertion that three to five million illegal votes were cast in the 2016 presidential election. But there is one study that has been interpreted to suggest it is at least possible. It found that between 32, 000 and 2. 8 million noncitizen voters might have fraudulently cast ballots in the 2008 presidential election. The study, based on a survey of 38, 000 people after that election, has been under fire since it was published in 2014. Now even its authors concede that it probably overstated the amount of noncitizen voting. \u201cThe   estimates are likely incorrect,\u201d Jesse Richman, one of the   of the study and a political science professor at Old Dominion University, said in an email exchange on Wednesday. In a post online, he also said that the findings do not support Mr. Trump\u2019s contention that millions cast ballots illegally. Mr. Richman still maintains that some small percentage of noncitizens vote in American elections. But the debate over this study has moved on. It\u2019s no longer about whether millions of illegal votes were cast, but whether there\u2019s any evidence for noncitizen voting at all. The study\u2019s bold claims fell apart because of something called response error: the possibility that people taking a survey don\u2019t answer a question correctly  \u2014   in this case, a question about being American citizens. There is always a tiny amount of response error in surveys. Respondents might not understand the question. Or they might understand it, but mark the wrong answer by mistake, if the survey is  . An interviewer, if there is one, could accidentally record the wrong answer. Such errors usually aren\u2019t a problem large enough to change the results of a survey. But both the survey and the question posed by researchers were unusual. The survey  \u2014   the Cooperative Congressional Election Study  \u2014   was huge, with 38, 000 respondents in 2008. And the group in question  \u2014   noncitizens  \u2014   was very small, just 339 of those respondents. The problem is that even a tiny amount of response error among the 38, 000 respondents could have been enough to contaminate the results of the tiny group of noncitizens. Imagine, for instance, that 99. 9 percent of people respond to the survey\u2019s citizenship question correctly. In such a big survey, even that high success rate would still imply that there were 38 respondents who answered incorrectly  \u2014   enough to make up a big chunk of the tiny pool of 339 noncitizen respondents. If those 38 misreported noncitizens had indeed voted, then suddenly it would look as if 10 percent of noncitizens voted. This critique could explain all of the noncitizen voting observed in the study. Critics of the study  \u2014   Stephen Ansolabehere, a Harvard political scientist, Samantha Luks, a statistician at YouGov, and Brian  Schaffner, a political scientist at the University of Massachusetts Amherst  \u2014   were able to marshal evidence strongly consistent with that possibility, because of the survey\u2019s unusual design: Thousands of voters are   in subsequent elections. That allowed the study\u2019s critics to check whether people were consistent about their answer on the citizenship answer from year to year. If the people were consistent, they were probably noncitizens. If voters were inconsistent, it would be a sign that the category was contaminated by the tiny number of voters who misreported their citizenship. There was not much consistency. Between 2010 and 2012, 20 voters switched from being citizens to noncitizens (an extremely unlikely transition) and 36 others switched from noncitizens to citizens (a more common transition, but one reported at a far greater rate than typically occurs). These shifting answers strongly bolster the theory that many of the respondents logged as noncitizens had responded in error. But most important, among the 85 respondents who said they were noncitizens in both 2010 and 2012  \u2014   those most likely to really be noncitizens  \u2014   none had voted in the 2010 midterm elections. The critics concluded that \u201cthe likely percent of noncitizen voters in recent U. S. elections is 0. \u201d In a response published in October, Mr. Richman and his colleagues did not contest the finding that measurement error probably exaggerated the number of noncitizen voters. \u201cThe response error issues they focus on may have biased our numbers,\u201d Mr. Richman said in an email to The New York Times on Wednesday. Mr. Richman and his colleagues have not estimated a new range of possible noncitizen voting. Instead, the October response sought only to rebut the notion that there was no noncitizen voting. They argued that measurement error couldn\u2019t explain all of the people who said they were noncitizens and voted. When it came to hard evidence immune to the measurement error critique, Mr. Richman and his   found one validated 2012 voter who had indicated not being a citizen in both the 2010 and 2012 surveys. But the same noncitizen had indicated in the survey that he or she was not registered to vote. The determination that he or she was a voter was based on voter records: The respondents to the survey were matched to a voter registration file. It is possible that this noncitizen was erroneously matched to the voter file. The matching process is good but imperfect, and becomes harder with less information  \u2014   like the absence of a specific address or date of birth. That the respondent said he or she wasn\u2019t registered certainly raises the possibility that the match was wrong. \u201cI haven\u2019t seen any evidence that I would say shows that any noncitizens vote,\u201d Mr. Schaffner said. \u201cThat doesn\u2019t mean that the rate is exactly zero. But it does mean that it\u2019s   frequency that we can\u2019t even measure it with traditional methods. \u201d'"}, "time": 1742564290.113782}