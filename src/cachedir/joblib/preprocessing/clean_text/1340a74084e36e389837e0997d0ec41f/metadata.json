{"duration": 0.1733684539794922, "input_args": {"text": "'LONDON  \u2014   Patrick Stobbs recently sat in a conference room here playing songs from his smartphone, attempting to show how his   Jukedeck, is at the cutting edge of music. The tune sounded like the soundtrack to a 1980s video game. \u201cThis is where we were two years ago,\u201d he said, looking slightly embarrassed. \u201cAnd this is where we are now,\u201d he continued. He then played a gentle piano piece. Its melody was simple, and it was unsubtle in its melancholy, but there was no denying that it could work as background music for, say, a health insurance commercial. Mr. Stobbs didn\u2019t write the music himself, nor did he commission it from a composer. Jukedeck is one of a growing number of companies using artificial intelligence to compose music. Their computers tap tools like artificial neural networks, modeled on the brain, that allow the machines to learn by doing, rather as a child does. So far, at least, these businesses do not seem to be causing much anxiety among musicians. \u201cWe see our system as still in its infancy it\u2019s only learnt a certain amount about music,\u201d Mr. Stobbs said, although he quickly hinted how he hoped Jukedeck\u2019s music could advance: \u201cThere\u2019s no rule of physics that says computers can\u2019t get as good as a human. \u201d Having machines write music is not new. In the 1950s, the composer Lejaren Hiller used a computer to produce the \u201cIlliac\u201d Suite for string quartet, the first   score. Since then, countless researchers have pushed that work forward. But several   are now trying to commercialize A. I. music for everything from jingles to potential pop hits. Jukedeck, for instance, is looking to sell tracks to anyone who needs background music for videos, games or commercials. The company charges large businesses just $21. 99 to use a track, a fraction of what hiring a musician would cost. Mr. Stobbs wouldn\u2019t reveal how many tracks it has sold, but said that the British division of   pays for a monthly subscription. Tech giants are also involved. In June, Google Brain announced Magenta, a project that aims to have computers produce \u201ccompelling and artistic\u201d music, filled with surprises. Its efforts so far do not quite fit the bill. In September, DeepMind, the   British artificial intelligence company, also released results of an experiment it undertook for fun. DeepMind put samples of piano music into its WaveNet system, used to generate audio, such as speech. The system, which was not told anything about how music worked, used the initial audio to synthesize   clips that sound like   jazz. IBM also has a research project called Watson Beat, which musicians will be able to use to transform their work\u2019s style, making songs sound Middle Eastern, for example, or \u201cspooky. \u201d Jukedeck\u2019s beginnings are somewhat surprising for a tech company. Mr. Stobbs and the composer Ed   both 29, founded it in 2012. They had been choristers at King\u2019s College School in Cambridge, England, and Mr.   went on to study music at the University of Cambridge, where he first learned that artificial intelligence could compose. After graduating from Cambridge, the pair set up a choral boy band (\u201ca terrible idea,\u201d Mr. Stobbs said) and had aspirations to run a record label. But in 2010, Mr.   attended a computer science lecture at Harvard, where his girlfriend was studying. The lecturer made coding sound relatively straightforward, and also made Mr.   recall his earlier studies in A. I. music. He decided to put the two together, and he set about building Jukedeck on the flight home. Jukedeck\u2019s system involves feeding hundreds of scores into its artificial neural networks, which then analyze them so they can work out things like the probability of one musical note\u2019s following another, or how chords progress. The networks can eventually produce compositions in a similar style, which are then turned into audio, using an automated production program. It has different networks for different styles, from folk to \u201ccorporate\u201d  \u2014   something that sounds like the glossy electronica typically played at business conferences. The company only recently started experimenting with the artificial neural networks for the audio output as well as the composition. This should make tracks sound more natural and varied  \u2014   more human, in other words. Other companies working on A. I. music tend to involve musicians more directly in the process. The Sony Computer Science Laboratory in Paris, for example, considers musicians essential to its Flow Machines project, which has received funding from the European Research Council. The idea behind the project is to get computers to write pop hits, said Fran\u00e7ois Pachet, the laboratory\u2019s director. \u201cMost people working on A. I. have focused on classical music, but I\u2019ve always been convinced that composing a short, catchy melody is probably the most difficult task,\u201d he said. He added: \u201cA compelling song is actually a rare and fragile object. It can only work if all the dimensions are right: the melody, the harmony, the voice, the dress of the singer, the discourse around it  \u2014   like, \u2018Why did you write this song?\u2019 No one is able to model all that right now, and I\u2019m interested in that problem. \u201d Flow Machines\u2019 main system is a composing tool that works similarly to Jukedeck\u2019s: by getting a computer to analyze scores  \u2014   everything from Beatles\u2019 songs to dance hits  \u2014   so that it can learn from them and write its own. However, its output is then given to musicians, who are free to use it, change it or throw it away as they like, at no charge. (Negotiations are underway regarding contractual obligations if record labels release any of this music.) Musicians give \u201ca sense of agency,\u201d Mr. Pachet said. \u201cThe systems don\u2019t know why they want to make music. They don\u2019t have any goal, any desire. \u201d Around 20 acts have already used the system, Mr. Pachet said, some performing the songs they wrote using it at a recent concert. He is in talks with some   groups, like the indie band Phoenix, to try it, he added, and several albums will be released this year. Musicians appear to enjoy it. \u201cI could never have written a song like the one I did without it,\u201d said Mathieu Peudupin, a French rock musician who goes by the name Lescop. \u201cIt drove me to a place I would never have gone myself. \u201d He said it was like working with a bandmate, although he ignored most of its suggestions. \u201cBut what singer in the world listens to his bandmates?\u201d he said, laughing. Mr. Pachet and Lescop both said they did not think listeners would ever entirely accept   music. \u201cMusic fans need to fall in love with musicians,\u201d Lescop said. \u201cYou can\u2019t fall in love with a computer. \u201d But the founders of Jukedeck are less certain. Mr.   sees artificial intelligence changing the way we listen, especially if computers eventually \u201cunderstand music enough to make it respond in real time to, let\u2019s say, a game, or you going for a run,\u201d he said. \u201cRecorded music\u2019s brilliant, but it\u2019s static. If you\u2019re playing a game, Hans Zimmer isn\u2019t sitting with you composing. I think responsive systems like that will be a big part of the music of the future. \u201d'"}, "time": 1742562674.9927197}